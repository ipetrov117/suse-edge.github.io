<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html><html xmlns="http://www.w3.org/1999/xhtml" lang="en"><head><title>SUSE Edge Documentation | Setting up the management cluster</title><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes"/><link rel="stylesheet" type="text/css" href="static/css/style.css"/>
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/"/><link rel="schema.DCTERMS" href="http://purl.org/dc/terms/"/>
<meta name="title" content="Setting up the management cluster"/>
<meta name="description" content="The management cluster is the part of ATIP that is used to manage the provision and lifecycle of the runtime stacks. From a technical point of view, …"/>
<meta name="book-title" content="SUSE Edge Documentation"/>
<meta name="chapter-title" content="Chapter 27. Setting up the management cluster"/>
<meta name="tracker-url" content="https://github.com/suse-edge/suse-edge.github.io/issues/new"/>
<meta name="tracker-type" content="gh"/>
<meta name="publisher" content="SUSE"/><meta property="og:title" content="Setting up the management cluster"/>
<meta property="og:description" content="The management cluster is the part of ATIP that is used to …"/>
<meta property="og:type" content="article"/>
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Setting up the management cluster"/>
<meta name="twitter:description" content="The management cluster is the part of ATIP that is used to …"/>
<script type="application/ld+json">{
    "@context": "http://schema.org",
    "@type": ["TechArticle"],
    "image": "https://www.suse.com/assets/img/suse-white-logo-green.svg",
    
    "inLanguage": "en",
    

    "headline": "Setting up the management cluster",
  
    "description": "Setting up the management cluster",
      
    "author": [
      {
        "@type": "Corporation",
        "name": "SUSE Product &amp; Solution Documentation Team",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    ],
      
    "dateModified": "2024-04-29T00:00+02:00",
      

    "about": [
      
    ],
  
    "sameAs": [
          "https://www.facebook.com/SUSEWorldwide/about",
          "https://www.youtube.com/channel/UCHTfqIzPKz4f_dri36lAQGA",
          "https://twitter.com/SUSE",
          "https://www.linkedin.com/company/suse"
    ],
    "publisher": {
      "@type": "Corporation",
      "name": "SUSE",
      "url": "https://documentation.suse.com",
      "logo": {
        "@type": "ImageObject",
        "url": "https://www.suse.com/assets/img/suse-white-logo-green.svg"
      }
    }
  }</script>
<link rel="prev" href="atip-requirements.html" title="Chapter 26. Requirements &amp; Assumptions"/><link rel="next" href="atip-features.html" title="Chapter 28. Telco features configuration"/><script type="text/javascript">

if ( window.location.protocol.toLowerCase() != 'file:' ) {
  document.write('<link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"></link>');
};

</script><noscript><link rel="stylesheet" type="text/css" href="https://documentation.suse.com/docserv/res/fonts/poppins/poppins.css"/></noscript><script src="static/js/script-purejs.js" type="text/javascript"> </script><script src="static/js/highlight.min.js" type="text/javascript"> </script><script>

$(document).ready(function() {
  $('.verbatim-wrap.highlight').each(function(i, block) {
    hljs.highlightBlock(block);
  });
});
hljs.configure({
  useBR: false
});

</script></head><body class="wide offline js-off"><div class="bypass-block"><a href="#_content">Jump to content</a><a href="#_bottom-pagination">Jump to page navigation: previous page [access key p]/next page [access key n]</a></div><header id="_mainnav"><div class="growth-inhibitor"><img src="static/images/logo.svg" alt="Logo" class="logo"/></div></header><div class="crumbs"><div class="growth-inhibitor"><a class="crumb" href="index.html">SUSE Edge Documentation</a><span> / </span><a class="crumb" href="id-product-documentation.html">Product Documentation</a><span> / </span><a class="crumb" href="atip-management-cluster.html">Setting up the management cluster</a></div></div><main id="_content"><nav id="_side-toc-overall" class="side-toc"><div class="side-title">SUSE Edge Documentation</div><ol><li><a href="id-suse-edge-documentation.html" class=" "><span class="title-number"> </span><span class="title-name">SUSE Edge Documentation</span></a></li><li><a href="id-quick-starts.html" class="has-children "><span class="title-number">I </span><span class="title-name">Quick Starts</span></a><ol><li><a href="quickstart-metal3.html" class=" "><span class="title-number">1 </span><span class="title-name">BMC automated deployments with Metal<sup>3</sup></span></a></li><li><a href="quickstart-elemental.html" class=" "><span class="title-number">2 </span><span class="title-name">Remote host onboarding with Elemental</span></a></li><li><a href="quickstart-eib.html" class=" "><span class="title-number">3 </span><span class="title-name">Standalone clusters with Edge Image Builder</span></a></li></ol></li><li><a href="id-components-used.html" class="has-children "><span class="title-number">II </span><span class="title-name">Components Used</span></a><ol><li><a href="components-rancher.html" class=" "><span class="title-number">4 </span><span class="title-name">Rancher</span></a></li><li><a href="components-rancher-dashboard-extensions.html" class=" "><span class="title-number">5 </span><span class="title-name">Rancher Dashboard Extensions</span></a></li><li><a href="components-fleet.html" class=" "><span class="title-number">6 </span><span class="title-name">Fleet</span></a></li><li><a href="components-slmicro.html" class=" "><span class="title-number">7 </span><span class="title-name">SLE Micro</span></a></li><li><a href="components-metal3.html" class=" "><span class="title-number">8 </span><span class="title-name">Metal<sup>3</sup></span></a></li><li><a href="components-eib.html" class=" "><span class="title-number">9 </span><span class="title-name">Edge Image Builder</span></a></li><li><a href="components-nmc.html" class=" "><span class="title-number">10 </span><span class="title-name">Edge Networking</span></a></li><li><a href="components-elemental.html" class=" "><span class="title-number">11 </span><span class="title-name">Elemental</span></a></li><li><a href="components-akri.html" class=" "><span class="title-number">12 </span><span class="title-name">Akri</span></a></li><li><a href="components-k3s.html" class=" "><span class="title-number">13 </span><span class="title-name">K3s</span></a></li><li><a href="components-rke2.html" class=" "><span class="title-number">14 </span><span class="title-name">RKE2</span></a></li><li><a href="components-longhorn.html" class=" "><span class="title-number">15 </span><span class="title-name">Longhorn</span></a></li><li><a href="components-neuvector.html" class=" "><span class="title-number">16 </span><span class="title-name">NeuVector</span></a></li><li><a href="components-metallb.html" class=" "><span class="title-number">17 </span><span class="title-name">MetalLB</span></a></li><li><a href="components-kubevirt.html" class=" "><span class="title-number">18 </span><span class="title-name">Edge Virtualization</span></a></li></ol></li><li><a href="id-how-to-guides.html" class="has-children "><span class="title-number">III </span><span class="title-name">How-To Guides</span></a><ol><li><a href="guides-metallb-k3s.html" class=" "><span class="title-number">19 </span><span class="title-name">MetalLB on K3s (using L2)</span></a></li><li><a href="guides-metallb-kubernetes.html" class=" "><span class="title-number">20 </span><span class="title-name">MetalLB in front of the Kubernetes API server</span></a></li><li><a href="id-air-gapped-deployments-with-edge-image-builder.html" class=" "><span class="title-number">21 </span><span class="title-name">Air-gapped deployments with Edge Image Builder</span></a></li></ol></li><li><a href="id-third-party-integration.html" class="has-children "><span class="title-number">IV </span><span class="title-name">Third-Party Integration</span></a><ol><li><a href="integrations-nats.html" class=" "><span class="title-number">22 </span><span class="title-name">NATS</span></a></li><li><a href="id-nvidia-gpus-on-sle-micro.html" class=" "><span class="title-number">23 </span><span class="title-name">NVIDIA GPUs on SLE Micro</span></a></li></ol></li><li class="active"><a href="id-product-documentation.html" class="has-children you-are-here"><span class="title-number">V </span><span class="title-name">Product Documentation</span></a><ol><li><a href="atip.html" class=" "><span class="title-number">24 </span><span class="title-name">SUSE Adaptive Telco Infrastructure Platform (ATIP)</span></a></li><li><a href="atip-architecture.html" class=" "><span class="title-number">25 </span><span class="title-name">Concept &amp; Architecture</span></a></li><li><a href="atip-requirements.html" class=" "><span class="title-number">26 </span><span class="title-name">Requirements &amp; Assumptions</span></a></li><li><a href="atip-management-cluster.html" class=" you-are-here"><span class="title-number">27 </span><span class="title-name">Setting up the management cluster</span></a></li><li><a href="atip-features.html" class=" "><span class="title-number">28 </span><span class="title-name">Telco features configuration</span></a></li><li><a href="atip-automated-provisioning.html" class=" "><span class="title-number">29 </span><span class="title-name">Fully automated directed network provisioning</span></a></li><li><a href="atip-lifecycle.html" class=" "><span class="title-number">30 </span><span class="title-name">Lifecycle actions</span></a></li></ol></li><li><a href="id-release-notes.html" class=" "><span class="title-number">A </span><span class="title-name">Release Notes</span></a></li> </ol> </nav><button id="_open-side-toc-overall" title="Contents"> </button><article class="documentation"><button id="_unfold-side-toc-page">On this page</button><section class="chapter" id="atip-management-cluster" data-id-title="Setting up the management cluster"><div class="titlepage"><div><div><div class="title-container"><h1 class="title"><span class="title-number-name"><span class="title-number">27 </span><span class="title-name">Setting up the management cluster</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#">#</a></h1><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><section class="sect1" id="id-introduction" data-id-title="Introduction"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">27.1 </span><span class="title-name">Introduction</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-introduction">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The management cluster is the part of ATIP that is used to manage the provision and lifecycle of the runtime stacks.
From a technical point of view, the management cluster contains the following components:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><code class="literal">SUSE Linux Enterprise Micro</code> as the OS. Depending on the use case, some configurations like networking, storage, users and kernel arguments can be customized.</p></li><li class="listitem"><p><code class="literal">RKE2</code> as the Kubernetes cluster. Depending on the use case, it can be configured to use specific CNI plugins, such as <code class="literal">Multus</code>, <code class="literal">Cilium</code>, etc.</p></li><li class="listitem"><p><code class="literal">Rancher</code> as the management platform to manage the lifecycle of the clusters.</p></li><li class="listitem"><p><code class="literal">Metal<sup>3</sup></code> as the component to manage the lifecycle of the bare metal nodes.</p></li><li class="listitem"><p><code class="literal">CAPI</code> as the component to manage the lifecycle of the Kubernetes clusters (downstream clusters). With ATIP, also the <code class="literal">RKE2 CAPI Provider</code> is used to manage the lifecycle of the RKE2 clusters (downstream clusters).</p></li></ul></div><p>With all components mentioned above, the management cluster can manage the lifecycle of downstream clusters, using a declarative approach to manage the infrastructure and applications.</p><div id="id-1.7.6.2.5" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>For more information about <code class="literal">SUSE Linux Enterprise Micro</code>, see: SLE Micro (<a class="xref" href="components-slmicro.html" title="Chapter 7. SLE Micro">Chapter 7, <em>SLE Micro</em></a>)</p><p>For more information about <code class="literal">RKE2</code>, see: RKE2 (<a class="xref" href="components-rke2.html" title="Chapter 14. RKE2">Chapter 14, <em>RKE2</em></a>)</p><p>For more information about <code class="literal">Rancher</code>, see: Rancher (<a class="xref" href="components-rancher.html" title="Chapter 4. Rancher">Chapter 4, <em>Rancher</em></a>)</p><p>For more information about <code class="literal">Metal<sup>3</sup></code>, see: Metal3 (<a class="xref" href="components-metal3.html" title="Chapter 8. Metal3">Chapter 8, <em>Metal<sup>3</sup></em></a>)</p></div></section><section class="sect1" id="id-steps-to-set-up-the-management-cluster" data-id-title="Steps to set up the management cluster"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">27.2 </span><span class="title-name">Steps to set up the management cluster</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-steps-to-set-up-the-management-cluster">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The following steps are necessary to set up the management cluster (using a single node):</p><div class="informalfigure"><div class="mediaobject"><a href="images/product-atip-mgmtcluster1.png"><img src="images/product-atip-mgmtcluster1.png" width="NaN" alt="product atip mgmtcluster1" title="product atip mgmtcluster1"/></a></div></div><p>There are two main steps to set up the management cluster using a declarative approach:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><span class="strong"><strong>Image creation</strong></span>: The first step is to create the image to be used for the management cluster with all the necessary configurations. This image is generated using <code class="literal">Edge Image Builder</code>, and this step can be done using a laptop, server, VM or any other x86_64 system with a container runtime installed.</p></li><li class="listitem"><p><span class="strong"><strong>Management cluster provision</strong></span>: This step covers the installation of the management cluster using the image created in the previous step. It installs all components mentioned in the introduction.</p></li></ul></div><div id="id-1.7.6.3.6" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>For more information about <code class="literal">Edge Image Builder</code>, see Edge Image Builder (<a class="xref" href="components-eib.html" title="Chapter 9. Edge Image Builder">Chapter 9, <em>Edge Image Builder</em></a>) and Edge Image Builder Quick Start (<a class="xref" href="quickstart-eib.html" title="Chapter 3. Standalone clusters with Edge Image Builder">Chapter 3, <em>Standalone clusters with Edge Image Builder</em></a>).</p></div></section><section class="sect1" id="id-image-preparation" data-id-title="Image preparation"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">27.3 </span><span class="title-name">Image preparation</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-image-preparation">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Using <code class="literal">Edge Image Builder</code> to create the image for the management cluster, a lot of configurations can be customized, but in this document, we cover the minimal configurations necessary to set up the management cluster.
Edge Image Builder is typically run from inside a container so, if you do not already have a way to run containers, we need to start by installing a container runtime such as <a class="link" href="https://podman.io" target="_blank">Podman</a> or <a class="link" href="https://rancherdesktop.io" target="_blank">Rancher Desktop</a>. For this guide, we assume you already have a container runtime available.</p><section class="sect2" id="id-directory-structure" data-id-title="Directory structure"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.1 </span><span class="title-name">Directory structure</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-directory-structure">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>When running the <code class="literal">EIB</code>, a directory is mounted from the host, so the first thing to do is to create a directory structure to be used by the <code class="literal">EIB</code> to store the configuration files and the image itself.
This directory has the following structure:</p><div class="verbatim-wrap"><pre class="screen">├── mgmt-cluster.yaml
├── base-images/
│   └ SLE-Micro.x86_64-5.5.0-Default-SelfInstall-GM2.install.iso
├── network/
|   └ mgmt-cluster-network.yaml
├── kubernetes/
|   └ config/
|   | └ server.yaml
└── custom/
    └ files/
    | └ clusterctl.yaml
    | └ helm-values-metal3.yaml
    | └ disable-embedded-capi.yaml
    └ scripts/
    | └ install-dependencies.sh</pre></div><div id="id-1.7.6.4.3.4" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>The image <code class="literal">SLE-Micro.x86_64-5.5.0-Default-SelfInstall-GM2.install.iso</code> has to be downloaded from the <a class="link" href="https://scc.suse.com/" target="_blank">SUSE Customer Center</a> or the <a class="link" href="https://www.suse.com/download/sle-micro/" target="_blank">SUSE Download page</a>, and it has to be located under the <code class="literal">base-images</code> folder.</p></div></section><section class="sect2" id="id-management-cluster-definition" data-id-title="Management cluster definition"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.2 </span><span class="title-name">Management cluster definition</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-management-cluster-definition">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The <code class="literal">mgmt-cluster.yaml</code> file is the main configuration file for the management cluster. It contains the following information:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">apiVersion: 1.0
image:
  imageType: iso
  arch: x86_64
  baseImage: SLE-Micro.x86_64-5.5.0-Default-SelfInstall-GM2.install.iso
  outputImageName: eib-mgmt-cluster-image.iso
operatingSystem:
  isoConfiguration:
    installDevice: /dev/sda
  users:
  - username: root
    encryptedPassword: ${ROOT_PASSWORD}
  packages:
    packageList:
    - git
    sccRegistrationCode: ${SCC_REGISTRATION_CODE}
kubernetes:
  version: ${KUBERNETES_VERSION}</pre></div><p>To explain the fields and values in the <code class="literal">mgmt-cluster.yaml</code> file, we have divided it into the following sections.</p></section><section class="sect2" id="id-image-section" data-id-title="Image section:"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.3 </span><span class="title-name">Image section:</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-image-section">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight yaml"><pre class="screen">image:
  imageType: iso
  arch: x86_64
  baseImage: SLE-Micro.x86_64-5.5.0-Default-SelfInstall-GM2.install.iso
  outputImageName: eib-mgmt-cluster-image.iso</pre></div><p>where the <code class="literal">baseImage</code> is the original image you downloaded from the SUSE Customer Center or the SUSE Download page. The <code class="literal">outputImageName</code> is the name of the new image that will be used to provision the management cluster.</p></section><section class="sect2" id="id-operating-system-section" data-id-title="Operating system section:"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.4 </span><span class="title-name">Operating system section:</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-operating-system-section">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight yaml"><pre class="screen">operatingSystem:
  isoConfiguration:
    installDevice: /dev/sda
    unattended: true
  users:
  - username: root
    encryptedPassword: ${ROOT_PASSWORD}
  packages:
    packageList:
    - git
  sccRegistrationCode: ${SCC_REGISTRATION_CODE}</pre></div><p>where the <code class="literal">installDevice</code> is the device to be used to install the operating system, the <code class="literal">unattended</code> is a flag to indicate if the installation is unattended, the <code class="literal">username</code> and <code class="literal">encryptedPassword</code> are the credentials to be used to access the system, the <code class="literal">packageList</code> is the list of packages to be installed and the <code class="literal">sccRegistrationCode</code> is the registration code to be used to register the system that can be obtained from the SUSE Customer Center.</p><p>The encrypted password can be generated using the <code class="literal">openssl</code> command as follows:</p><div class="verbatim-wrap"><pre class="screen">openssl passwd -6 MyPassword!123</pre></div><p>This outputs something similar to:</p><div class="verbatim-wrap"><pre class="screen">$6$UrXB1sAGs46DOiSq$HSwi9GFJLCorm0J53nF2Sq8YEoyINhHcObHzX2R8h13mswUIsMwzx4eUzn/rRx0QPV4JIb0eWCoNrxGiKH4R31</pre></div></section><section class="sect2" id="id-kubernetes-section" data-id-title="Kubernetes section:"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.5 </span><span class="title-name">Kubernetes section:</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-kubernetes-section">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><div class="verbatim-wrap highlight yaml"><pre class="screen">kubernetes:
  version: ${KUBERNETES_VERSION}</pre></div><p>where <code class="literal">version</code> is the version of Kubernetes to be installed. In our case, we are using an RKE2 cluster, so the version has to be minor than 1.29 to be compatible with <code class="literal">Rancher</code> (for example, <code class="literal">v1.28.8+rke2r1</code>).</p></section><section class="sect2" id="mgmt-cluster-helm-values" data-id-title="Custom files section:"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.6 </span><span class="title-name">Custom files section:</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#mgmt-cluster-helm-values">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The <code class="literal">custom/files</code> folder contains the following files:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><code class="literal">helm-values-metal3.yaml</code>: contains the configuration parameters about the <code class="literal">Metal<sup>3</sup></code> Helm chart to be used.</p></li><li class="listitem"><p><code class="literal">clusterctl.yaml</code>: contains the configuration parameters about the <code class="literal">CAPI</code> Helm chart to be used.</p></li><li class="listitem"><p><code class="literal">disable-embedded-capi.yaml</code>: contains the configuration parameters to disable the embedded <code class="literal">CAPI</code> component.</p></li></ul></div><p>The following variables have to be replaced:</p><p><code class="literal">${MGMT_CLUSTER_IP}</code>: The IP address of the management cluster.</p><div id="metal3-media-server" class="admonition note normal"><img class="symbol" alt="Note" title="Note" src="static/images/icon-note.svg"/><div class="admon-title">Note</div><p>The Media Server is an optional feature included in Metal<sup>3</sup>. To use your own media server (file server), disable <code class="literal">enable_metal3_media_server</code> on the following manifest.
To use the Metal<sup>3</sup> media server, specify the following variable:
<code class="literal">${MEDIA_VOLUME_PATH}</code> — the path to the media volume to be used by the <code class="literal">Metal<sup>3</sup></code> component (for example, <code class="literal">/home/metal3/bmh-image-cache</code>).</p></div><p>The <code class="literal">helm-values-metal3.yaml</code> file:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">global:
  ironicIP: ${MGMT_CLUSTER_IP}
  enable_vmedia_tls: false
  enable_metal3_media_server: true

metal3-media:
  service:
    type: NodePort
    port: 6280

metal3-ironic:
  global:
    predictableNicNames: "true"
  service:
    type: NodePort

metal3-media:
  mediaVolume:
    hostPath: ${MEDIA_VOLUME_PATH}</pre></div><p>The <code class="literal">clusterctl.yaml</code> file:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">images:
  all:
    repository: registry.opensuse.org/isv/suse/edge/clusterapi/containerfile/suse</pre></div><p>The <code class="literal">disable-embedded-capi.yaml</code> file:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">apiVersion: management.cattle.io/v3
kind: Feature
metadata:
  name: embedded-cluster-api
spec:
  value: false</pre></div></section><section class="sect2" id="id-custom-scripts-section" data-id-title="Custom scripts section:"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.7 </span><span class="title-name">Custom scripts section:</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-custom-scripts-section">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>The <code class="literal">custom/scripts</code> folder contains the following files:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>The <code class="literal">install-dependencies.sh</code> script contains the commands to install essential dependencies required for the management cluster, such as <code class="literal">Rancher</code>, <code class="literal">Metal<sup>3</sup></code>, <code class="literal">Cert-Manager</code>, etc.:</p></li></ul></div><p>The following steps are executed by the <code class="literal">install-dependencies.sh</code> script:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p>Create the folder to enable the media server for the <code class="literal">Metal<sup>3</sup></code> component.</p></li><li class="listitem"><p>Copy the <code class="literal">helm-values-metal3.yaml</code> file to the <code class="literal">Metal<sup>3</sup></code> folder.</p></li><li class="listitem"><p>Create the installer script to install the necessary tools, like clusterctl, helm for the management cluster.</p></li><li class="listitem"><p>Wait for the cluster to be available.</p></li><li class="listitem"><p>Install the <code class="literal">Cert-Manager</code> component.</p></li><li class="listitem"><p>Install the <code class="literal">Local-Path-Provisioner</code> component (for a single-node cluster).</p></li><li class="listitem"><p>Install the <code class="literal">Rancher Prime</code> component.</p></li><li class="listitem"><p>Install the <code class="literal">Metal<sup>3</sup></code> component.</p></li><li class="listitem"><p>Install the <code class="literal">CAPI</code> component.</p></li><li class="listitem"><p>Create the systemd service to run the installer script during the first boot.</p></li></ul></div><p>The <code class="literal">install-dependencies.sh</code> script is as follows:</p><div class="verbatim-wrap"><pre class="screen">#!/bin/bash

mount /usr/local || true
mount /home || true

## create folder to server httpd media server
mkdir -p /home/metal3/bmh-image-cache

## copy the metal3 yaml file to metal3 folder
cp ./helm-values-metal3.yaml ./clusterctl.yaml ./disable-embedded-capi.yaml /home/metal3/

## KUBECTL command var
export KUBECTL=/var/lib/rancher/rke2/bin/kubectl

# Create the installer script
cat &lt;&lt;- EOF &gt; /usr/local/bin/mgmt-cluster-installer.sh
#!/bin/bash
set -euo pipefail

## install clusterctl and helm
curl -Lk https://github.com/kubernetes-sigs/cluster-api/releases/download/v1.6.0/clusterctl-linux-amd64 -o /usr/local/bin/clusterctl
chmod +x /usr/local/bin/clusterctl
curl https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3 | bash

## Wait for RKE2 cluster to be available
until [ -f /etc/rancher/rke2/rke2.yaml ]; do sleep 2; done
# export the kubeconfig using the right kubeconfig path depending on the cluster (k3s or rke2)
export KUBECONFIG=/etc/rancher/rke2/rke2.yaml
# Wait for the node to be available, meaning the K8s API is available
while ! ${KUBECTL} wait --for condition=ready node $(hostname | tr '[:upper:]' '[:lower:]') ; do sleep 2 ; done

## Add Helm repos
helm repo add rancher-prime https://charts.rancher.com/server-charts/prime
helm repo add jetstack https://charts.jetstack.io
helm repo update

while ! ${KUBECTL} rollout status daemonset -n kube-system rke2-ingress-nginx-controller ; do sleep 2 ; done

## install cert-manager
helm install cert-manager jetstack/cert-manager \
	--namespace cert-manager \
        --create-namespace \
        --set installCRDs=true \
	--version v1.11.1

## Local path provisioner
${KUBECTL} apply -f https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.26/deploy/local-path-storage.yaml
until [ \$(${KUBECTL} get sc -o name | wc -l) -ge 1 ]; do sleep 10; done
${KUBECTL} patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

## Example in case you want to configure the httpd cache server for images
## podman run -dit --name bmh-image-cache -p 8080:80 -v /home/metal3/bmh-image-cache:/usr/local/apache2/htdocs/ docker.io/library/httpd:2.4

## install rancher
helm install rancher rancher-prime/rancher \
	--namespace cattle-system \
	--create-namespace \
	--set hostname=rancher-$(hostname -I | awk '{print $1}').sslip.io \
	--set bootstrapPassword=admin \
	--set replicas=1 \
        --set global.cattle.psp.enabled=false
while ! ${KUBECTL} wait --for condition=ready -n cattle-system \$(${KUBECTL} get pods -n cattle-system -l app=rancher -o name) --timeout=10s; do sleep 2 ; done

## install metal3 with helm
helm install metal3 oci://registry.suse.com/edge/metal3-chart --namespace metal3-system --create-namespace -f /home/metal3/helm-values-metal3.yaml


## install capi
if [ \$(${KUBECTL} get pods -n cattle-system -l app=rancher -o name | wc -l) -ge 1 ]; then
	${KUBECTL} apply -f /home/metal3/disable-embedded-capi.yaml
	${KUBECTL} delete mutatingwebhookconfiguration.admissionregistration.k8s.io mutating-webhook-configuration
	${KUBECTL} delete validatingwebhookconfigurations.admissionregistration.k8s.io validating-webhook-configuration
	${KUBECTL} wait --for=delete namespace/cattle-provisioning-capi-system --timeout=300s
fi
clusterctl init --core "cluster-api:v1.6.2" --infrastructure "metal3:v1.6.0" --bootstrap "rke2:v0.2.6" --control-plane "rke2:v0.2.6" --config /home/metal3/clusterctl.yaml

rm -f /etc/systemd/system/mgmt-cluster-installer.service
EOF

chmod a+x /usr/local/bin/mgmt-cluster-installer.sh

cat &lt;&lt;- EOF &gt; /etc/systemd/system/mgmt-cluster-installer.service
[Unit]
Description=Deploy mgmt cluster tools on K3S/RKE2
Wants=network-online.target
After=network.target network-online.target rke2-server.target
ConditionPathExists=/usr/local/bin/mgmt-cluster-installer.sh

[Service]
User=root
Type=forking
TimeoutStartSec=900
ExecStart=/usr/local/bin/mgmt-cluster-installer.sh
RemainAfterExit=yes
KillMode=process
# Disable &amp; delete everything
ExecStartPost=rm -f /usr/local/bin/mgmt-cluster-installer.sh
ExecStartPost=/bin/sh -c "systemctl disable mgmt-cluster-installer.service"
ExecStartPost=rm -f /etc/systemd/system/mgmt-cluster-installer.service

[Install]
WantedBy=multi-user.target
EOF

systemctl enable mgmt-cluster-installer.service

umount /usr/local || true
umount /home || true</pre></div></section><section class="sect2" id="id-kubernetes-definition-optional" data-id-title="Kubernetes definition (optional)"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.8 </span><span class="title-name">Kubernetes definition (optional)</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-kubernetes-definition-optional">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>By default, the <code class="literal">CNI</code> plugin installed by default is <code class="literal">Cilium</code>, so you do not need to create this file. Just in case you need to customize the <code class="literal">CNI</code> plugin, you can use the <code class="literal">server.yaml</code> file under the <code class="literal">kubernetes/config</code> folder. It contains the following information:</p><div class="verbatim-wrap highlight yaml"><pre class="screen">cni:
- multus
- cilium</pre></div><p>This is an optional file to define certain Kubernetes customization, like the CNI plug-ins to be used or many options you can check in the <a class="link" href="https://docs.rke2.io/install/configuration" target="_blank">official documentation</a>.</p></section><section class="sect2" id="id-networking-definition-optional" data-id-title="Networking definition (optional)"><div class="titlepage"><div><div><div class="title-container"><h3 class="title"><span class="title-number-name"><span class="title-number">27.3.9 </span><span class="title-name">Networking definition (optional)</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-networking-definition-optional">#</a></h3><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>If you need to customize the networking configuration, for example, to use a specific IP address (DHCP-less scenario), you can use the <code class="literal">mgmt-cluster-network.yaml</code> file under the <code class="literal">network</code> folder. It contains the following information:</p><div class="itemizedlist"><ul class="itemizedlist"><li class="listitem"><p><code class="literal">${MGMT_GATEWAY}</code>: The gateway IP address.</p></li><li class="listitem"><p><code class="literal">${MGMT_DNS}</code>: The DNS server IP address.</p></li><li class="listitem"><p><code class="literal">${MGMT_MAC}</code>: The MAC address of the network interface.</p></li><li class="listitem"><p><code class="literal">${MGMT_CLUSTER_IP}</code>: The IP address of the management cluster.</p></li></ul></div><div class="verbatim-wrap highlight yaml"><pre class="screen">routes:
  config:
  - destination: 0.0.0.0/0
    metric: 100
    next-hop-address: ${MGMT_GATEWAY}
    next-hop-interface: eth0
    table-id: 254
dns-resolver:
  config:
    server:
    - ${MGMT_DNS}
    - 8.8.8.8
interfaces:
- name: eth0
  type: ethernet
  state: up
  mac-address: ${MGMT_MAC}
  ipv4:
    address:
    - ip: ${MGMT_CLUSTER_IP}
      prefix-length: 24
    dhcp: false
    enabled: true
  ipv6:
    enabled: false</pre></div></section></section><section class="sect1" id="id-image-creation" data-id-title="Image creation"><div class="titlepage"><div><div><div class="title-container"><h2 class="title"><span class="title-number-name"><span class="title-number">27.4 </span><span class="title-name">Image creation</span></span> <a title="Permalink" class="permalink" href="atip-management-cluster.html#id-image-creation">#</a></h2><div class="icons"><a target="_blank" class="icon-reportbug" title="Report an issue"> </a></div></div></div></div></div><p>Once the directory structure is prepared following the previous sections, run the following command to build the image:</p><div class="verbatim-wrap"><pre class="screen">podman run --rm --privileged -it -v $PWD:/eib \
 registry.suse.com/edge/edge-image-builder:1.0.1 \
 build --definition-file mgmt-cluster.yaml</pre></div><p>This creates the ISO output image file that, in our case, based on the image definition described above, is <code class="literal">eib-mgmt-cluster-image.iso</code>.
This image contains all components inside, and it can be used to provision the management cluster using a virtual machine or a bare-metal server (using the virtual-media feature).</p></section></section><nav class="bottom-pagination"><div><a class="pagination-link prev" href="atip-requirements.html"><span class="pagination-relation">Previous</span><span class="pagination-label"><span class="title-number">Chapter 26 </span>Requirements &amp; Assumptions</span></a> </div><div><a class="pagination-link next" href="atip-features.html"><span class="pagination-relation">Next</span><span class="pagination-label"><span class="title-number">Chapter 28 </span>Telco features configuration</span></a> </div></nav></article><aside id="_side-toc-page" class="side-toc"><div class="side-title">On this page</div><div class="toc"><ul><li><span class="section"><a href="atip-management-cluster.html#id-introduction"><span class="title-number">27.1 </span><span class="title-name">Introduction</span></a></span></li><li><span class="section"><a href="atip-management-cluster.html#id-steps-to-set-up-the-management-cluster"><span class="title-number">27.2 </span><span class="title-name">Steps to set up the management cluster</span></a></span></li><li><span class="section"><a href="atip-management-cluster.html#id-image-preparation"><span class="title-number">27.3 </span><span class="title-name">Image preparation</span></a></span></li><li><span class="section"><a href="atip-management-cluster.html#id-image-creation"><span class="title-number">27.4 </span><span class="title-name">Image creation</span></a></span></li></ul></div><div class="side-title">Share this page</div><ul class="share"><li><a id="_share-fb" href="#" title="Facebook"> </a></li><li><a id="_share-in" href="#" title="LinkedIn"> </a></li><li><a id="_share-tw" href="#" title="Twitter/X"> </a></li><li><a id="_share-mail" href="#" title="E-Mail"> </a></li><li><a id="_print-button" href="#" title="Print this page"> </a></li></ul> </aside></main><footer id="_footer"><div class="growth-inhibitor"><div class="copy"><span class="copy__rights">© SUSE
                 2024</span></div></div></footer></body></html>